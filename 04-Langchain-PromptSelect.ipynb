{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e89d5cd",
   "metadata": {},
   "source": [
    "# Prompt Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3daa962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "# 創建反義詞任務\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"hot\", \"output\": \"cold\"},\n",
    "    {\"input\": \"up\", \"output\": \"down\"},\n",
    "    {\"input\": \"big\", \"output\": \"small\"},\n",
    "    {\"input\": \"fast\", \"output\": \"slow\"},\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\"\n",
    ")\n",
    "\n",
    "examples_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=50,  # 設定最大長度\n",
    ")\n",
    "\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=examples_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Please provide the antonym for the following word:\\n\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efea179c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the antonym for the following word:\n",
      "\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: hot\n",
      "Output: cold\n",
      "\n",
      "Input: up\n",
      "Output: down\n",
      "\n",
      "Input: big\n",
      "Output: small\n",
      "\n",
      "Input: fast\n",
      "Output: slow\n",
      "\n",
      "Input: happy\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(dynamic_prompt.format(adjective=\"happy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793954f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the antonym for the following word:\n",
      "\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: hot\n",
      "Output: cold\n",
      "\n",
      "Input: up\n",
      "Output: down\n",
      "\n",
      "Input: big\n",
      "Output: small\n",
      "\n",
      "Input: fast\n",
      "Output: slow\n",
      "\n",
      "Input: This is a long and short, big but small article.\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "long_text = \"This is a long and short, big but small article.\"\n",
    "print(dynamic_prompt.format(adjective=long_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509898c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the antonym for the following word:\n",
      "\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: hot\n",
      "Output: cold\n",
      "\n",
      "Input: up\n",
      "Output: down\n",
      "\n",
      "Input: big\n",
      "Output: small\n",
      "\n",
      "Input: fast\n",
      "Output: slow\n",
      "\n",
      "Input: light\n",
      "Output: heavy\n",
      "\n",
      "Input: light\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "new_examples = {\"input\": \"light\", \"output\": \"heavy\"}\n",
    "dynamic_prompt.example_selector.add_example(new_examples)\n",
    "print(dynamic_prompt.format(adjective=\"light\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e0eada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9081781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The antonym for the word \"light\" is actually \"dark\", not \"heavy\". Heavy and dark are related but distinct concepts.\\n\\nSo, the corrected output would be:\\n\\n Input: light\\nOutput: dark'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "openai_api_key = os.getenv(\"EMPTY\")\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=openai_api_key,\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0.7,\n",
    "    openai_api_base=\"http://127.0.0.1:11434/v1\",\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = dynamic_prompt | chat | output_parser\n",
    "\n",
    "chain.invoke({\"adjective\": \"light\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de01445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.example_selector import (MaxMarginalRelevanceExampleSelector, SemanticSimilarityExampleSelector) \n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_path = \"D:\\\\ai\\\\downloads\\\\bge-large-zh-v1.5\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embeddings_path)\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\"\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"hot\", \"output\": \"cold\"},\n",
    "    {\"input\": \"up\", \"output\": \"down\"},\n",
    "    {\"input\": \"big\", \"output\": \"small\"},\n",
    "    {\"input\": \"fast\", \"output\": \"slow\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d52e4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain_2025_twh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
